{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install openai\n",
    "!python3 -m pip install gradio\n",
    "!python3 -m pip install --upgrade jupyter ipywidgets\n",
    "!python3 -m pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "from config import json_format\n",
    "\n",
    "# Update the BaseURL of the model (we are using the service name)\n",
    "# $ kubectl get service\n",
    "agent_base_url = \"http://llama3/v1\"\n",
    "code_base_url = \"http://codellama/v1\"\n",
    "optimization_base_url = \"http://cuopt-cuopt-deployment-cuopt-service:5000/cuopt/routes\"\n",
    "\n",
    "# Define parameters for different models\n",
    "agent_model_config = {\n",
    "    \"base_url\": agent_base_url,\n",
    "    \"api_key\": \"dummy\",\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "code_model_config = {\n",
    "    \"base_url\": code_base_url,\n",
    "    \"api_key\": \"dummy\",\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 256,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "\n",
    "# Cache for discovered models\n",
    "cached_models = {}\n",
    "\n",
    "def discover_model(client):\n",
    "    if client in cached_models:\n",
    "        return cached_models[client]\n",
    "    \n",
    "    available_models = client.models.list()\n",
    "    if len(available_models.data):\n",
    "        model = available_models.data[0].id\n",
    "        print(f\"Discovered model is: {model}\")\n",
    "        cached_models[client] = model\n",
    "    else:\n",
    "        print(\"No model discovered\")\n",
    "        sys.exit(1)\n",
    "    return model\n",
    "\n",
    "def create_completion(client, messages, config):\n",
    "    model = discover_model(client)\n",
    "    if model is None:\n",
    "        return []\n",
    "    try:\n",
    "        return client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=config[\"temperature\"],\n",
    "            top_p=config[\"top_p\"],\n",
    "            max_tokens=config[\"max_tokens\"],\n",
    "            stream=config[\"stream\"]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        return []\n",
    "\n",
    "def get_decision_from_agent(query):\n",
    "    system_messages = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Please classify the following query into one of the three categories: 'code', 'optimization', or 'general'. 'code' for queries asking for code examples, programming syntax, or specific implementation details. 'optimization' for queries related to improving performance, enhancing efficiency, or refining algorithms. 'general' for queries that do not specifically pertain to coding or optimization but instead involve general concepts, explanations, or broad questions. Answer only with 'code', 'optimization', or 'general':\"\n",
    "    }\n",
    "    user_messages = {\"role\": \"user\", \"content\": query}\n",
    "    messages = [system_messages, user_messages]\n",
    "    response = create_completion(client_agent, messages, {**agent_model_config, \"max_tokens\": 10})\n",
    "    decision = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            decision += chunk.choices[0].delta.content\n",
    "    return decision.strip().lower()\n",
    "\n",
    "def get_general_response_from_agent(query):\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    response = create_completion(client_agent, messages, agent_model_config)\n",
    "    agent_response = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            agent_response += chunk.choices[0].delta.content\n",
    "    return agent_response\n",
    "\n",
    "def get_response_from_code_model(query):\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    response = create_completion(client_code, messages, code_model_config)\n",
    "    codemodel_response = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            codemodel_response += chunk.choices[0].delta.content\n",
    "    return codemodel_response.strip().lower()\n",
    "\n",
    "def prepare_optimization_input(query):\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f'''You need to generate a payload for cuOpt to be able to answer the Question. Bellow is the structure of the json {json_format}, and you need to capture the values from the Question and populate the JSON.\n",
    "        The question will be like this: Optimize the routes for three delivery trucks. Truck 1 has a capacity of 4 units and starts at location [0, 0]. Truck 2 has a capacity of 6 units and starts at location [0, 0]. Truck 3 has a capacity of 2 units and starts at location [0, 0]. They need to deliver packages to locations [2, 2] with a demand of 1 unit, [4, 4] with a demand of 3 units, and [6, 6] with a demand of 2 units. All the locations have a time window from 0 to 1080, and the service time at each location is 1 units. The cost to travel between each location is provided in the following cost matrix: from [0, 0] to [2, 2] costs 10, from [0, 0] to [4, 4] costs 20, from [0, 0] to [6, 6] costs 30, from [2, 2] to [4, 4] costs 10, from [2, 2] to [6, 6] costs 20, from [4, 4] to [6, 6] costs 10. This is the expected JSON output for the example question: {{\"cost_matrix_data\":{{\"data\":{{\"0\":[[0,10,20,30],[10,0,10,20],[20,10,0,10],[30,20,10,0]]}}}},\"task_data\":{{\"task_locations\":[1,2,3],\"demand\":[[1,3,2]],\"task_time_windows\":[[0,1080],[0,1080],[0,1080]],\"service_times\":[1,1,1]}},\"fleet_data\":{{\"vehicle_locations\":[[0,0],[0,0],[0,0]],\"capacities\":[[4,6,2]],\"vehicle_time_windows\":[[0,1080],[0,1080],[0,1080]]}},\"solver_config\":{{\"time_limit\":2}}}}.\n",
    "        Another example of question is:Optimize the delivery routes for two delivery trucks. Truck 1 has a capacity of 15 units and starts at location [0, 0]. Truck 2 has a capacity of 3 units and starts at location [0, 0]. They need to deliver packages to locations [2, 2] with a demand of 2 units and [3, 3] with a demand of 15 unit. Both locations have a time window from 0 to 1080, and the service time at each location is 1 unit. The cost to travel between each location is provided in the following cost matrix: from [0, 0] to [2, 2] costs 10, from [0, 0] to [3, 3] costs 15, from [2, 2] to [3, 3] costs 35. This is the expected JSON for the second example question: {{\"cost_matrix_data\":{{\"data\":{{\"0\":[[0,10,15],[10,0,35],[15,35,0]]}}}},\"task_data\":{{\"task_locations\":[1,2],\"demand\":[[2,15]],\"task_time_windows\":[[0,1080],[0,1080]],\"service_times\":[1,1]}},\"fleet_data\":{{\"vehicle_locations\":[[0,0],[0,0]],\"capacities\":[[15,3]],\"vehicle_time_windows\":[[0,1080],[0,1080]]}},\"solver_config\":{{\"time_limit\":2}}}}.\n",
    "        Respond only with the JSON. Do not include any additional text.\n",
    "        When generating the JSON don`t change the provided JSON structure. The only exception is the cost_matrix_data where the number of locations define the dimension of the square matrix. It needs to contains one list for each locatation, and the lenght of each list is the total number of locations.\n",
    "        Learn to identify the correct intergers in the question provided as example and generate the JSON for the next question. \n",
    "        Question: {query}'''\n",
    "    }]\n",
    "    response = create_completion(client_agent, messages, agent_model_config)\n",
    "    payload_response = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            payload_response += chunk.choices[0].delta.content\n",
    "    return payload_response.strip().lower()\n",
    "\n",
    "\n",
    "def get_response_from_optimization(query):\n",
    "    generated_text = prepare_optimization_input(query)\n",
    "    log = \"----------------------\\n\"\n",
    "    log += f\"JSON generated by Llama3 that will be passed to Optimization Agent(CuOpt):\\n{generated_text}\\n\"\n",
    "    print(generated_text)\n",
    "\n",
    "    try:\n",
    "        cuopt_payload = json.loads(generated_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to parse generated text:\", e)\n",
    "        cuopt_payload = None\n",
    "    \n",
    "    optimized_routes = \"Failed to generate optimized routes.\"\n",
    "    if cuopt_payload:\n",
    "    # Send the payload to cuOpt\n",
    "        response_cuopt = requests.post(optimization_base_url, json=cuopt_payload)\n",
    "        if response_cuopt.status_code == 200:\n",
    "            optimized_routes = response_cuopt.json()\n",
    "        else:\n",
    "            print(\"Failed:\", response_cuopt.status_code, response_cuopt.text)\n",
    "    else:\n",
    "        print(\"Invalid payload generated by Agent Workflow.\")\n",
    "    return optimized_routes, log\n",
    "\n",
    "def get_preliminary_response(query):\n",
    "    decision = get_decision_from_agent(query)\n",
    "    log = f\"Decision by Agent Workflow: '{decision}'\\n\"\n",
    "    log += \"----------------------\\n\"\n",
    "    \n",
    "    if \"code\" in decision:\n",
    "        log += \"Response generated by: Code Agent(CodeLlama)\\n\"\n",
    "        log += \"----------------------\\n\"\n",
    "        response = get_response_from_code_model(query)\n",
    "    elif \"optimization\" in decision:\n",
    "        response, optimization_log = get_response_from_optimization(query)\n",
    "        log += optimization_log\n",
    "        log += \"Response generated by: Optimization Agent(CuOpt)\\n\"\n",
    "        log += \"----------------------\\n\"\n",
    "    else:\n",
    "        log += \"Response generated by: General Agent(Llama3)\\n\"\n",
    "        log += \"----------------------\\n\"\n",
    "        response = get_general_response_from_agent(query)\n",
    "    \n",
    "    log += f\"Preliminary response:\\n{response}\\n\"\n",
    "    log += \"----------------------\\n\"\n",
    "    return response, log\n",
    "\n",
    "def get_final_response_from_agent_workflow(query, preliminary_response):\n",
    "    system_messages = {\"role\": \"system\", \"content\": f\"Add the {preliminary_response} at the begining of the answer. Use this information {preliminary_response} and generate the response for the question:\"}\n",
    "    user_messages = {\"role\": \"user\", \"content\": query}\n",
    "    messages = [system_messages, user_messages]\n",
    "    final_response = create_completion(client_agent, messages, agent_model_config)\n",
    "    final_response_text = \"\"\n",
    "    for chunk in final_response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            final_response_text += chunk.choices[0].delta.content\n",
    "    return final_response_text\n",
    "\n",
    "def gradio_interface(query):\n",
    "    preliminary_response, log = get_preliminary_response(query)\n",
    "    final_response = get_final_response_from_agent_workflow(query, preliminary_response)\n",
    "    log += f\"Final response:\\n{final_response}\"\n",
    "    log += \"----------------------\\n\"\n",
    "    return log\n",
    "\n",
    "def set_api_keys(agent_key, code_key):\n",
    "    global agent_model_config, code_model_config\n",
    "    agent_model_config[\"api_key\"] = agent_key\n",
    "    code_model_config[\"api_key\"] = code_key\n",
    "    return agent_model_config, code_model_config\n",
    "\n",
    "def client_init(agent_config, code_config):\n",
    "    client_agent = OpenAI(\n",
    "        base_url=agent_config[\"base_url\"],\n",
    "        api_key=agent_config[\"api_key\"]\n",
    "    )\n",
    "    client_code = OpenAI(\n",
    "        base_url=code_config[\"base_url\"],\n",
    "        api_key=code_config[\"api_key\"]\n",
    "    )\n",
    "    return client_agent, client_code\n",
    "\n",
    "def set_keys_and_init_clients(agent_key, code_key):\n",
    "    agent_config, code_config = set_api_keys(agent_key, code_key)\n",
    "    global client_agent, client_code\n",
    "    client_agent, client_code = client_init(agent_config, code_config)\n",
    "    return \"API keys set and clients initialized.\"\n",
    "\n",
    "api_key_interface = gr.Interface(\n",
    "    fn=set_keys_and_init_clients,\n",
    "    inputs=[gr.Textbox(type=\"password\", placeholder=\"Enter agent API key\"), gr.Textbox(type=\"password\", placeholder=\"Enter code API key\")],\n",
    "    outputs=\"text\",\n",
    "    title=\"Set API Keys\",\n",
    "    description=\"Input the API keys for the agent and code models.\"\n",
    ")\n",
    "workflow_interface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Agent Workflow\",\n",
    "    description=\"Enter your query below:\"\n",
    ")\n",
    "\n",
    "gr.TabbedInterface([api_key_interface, workflow_interface], [\"Set API Keys\", \"Agent Workflow\"]).launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of questions for cuopt agent:\n",
    "Optimize the delivery routes for two delivery trucks. Truck 1 has a capacity of 15 units and starts at location [0, 0]. Truck 2 has a capacity of 3 units and starts at location [0, 0]. They need to deliver packages to locations [2, 2] with a demand of 2 units and [3, 3] with a demand of 15 unit. Both locations have a time window from 0 to 1080, and the service time at each location is 1 unit. The cost to travel between each location is provided in the following cost matrix: from [0, 0] to [2, 2] costs 10, from [0, 0] to [3, 3] costs 15, from [2, 2] to [3, 3] costs 35.\n",
    "Optimize the routes for three delivery trucks. Truck 1 has a capacity of 4 units and starts at location [0, 0]. Truck 2 has a capacity of 6 units and starts at location [0, 0]. Truck 3 has a capacity of 2 units and starts at location [0, 0]. They need to deliver packages to locations [2, 2] with a demand of 1 unit, [4, 4] with a demand of 3 units, and [6, 6] with a demand of 2 units. All the locations have a time window from 0 to 1080, and the service time at each location is 1 units. The cost to travel between each location is provided in the following cost matrix: from [0, 0] to [2, 2] costs 10, from [0, 0] to [4, 4] costs 20, from [0, 0] to [6, 6] costs 30, from [2, 2] to [4, 4] costs 10, from [2, 2] to [6, 6] costs 20, from [4, 4] to [6, 6] costs 10.\n",
    "Optimize the delivery route for one delivery truck. The truck 1 has a capacity of 2 units and starts at location [0,0]. It need to deliver packages to locations [2, 2] with a demand of 1 unit. The location have a time window from 0 to 1080, and the service time at each location is 1 unit. The cost to travel from [0, 0] to [2, 2] costs 10.\n",
    "Optimize the routes for four delivery trucks. Truck 1 has a capacity of 10 units and starts at location [0, 0]. Truck 2 has a capacity of 8 units and starts at location [0, 0]. Truck 3 has a capacity of 5 units and starts at location [0, 0]. Truck 4 has a capacity of 7 units and starts at location [0, 0]. They need to deliver packages to locations [2, 2] with a demand of 3 units, [4, 4] with a demand of 4 units, [6, 6] with a demand of 2 units, and [8, 8] with a demand of 5 units. All the locations have a time window from 0 to 1080, and the service time at each location is 1 unit. The cost to travel between each location is provided in the following cost matrix: from [0, 0] to [2, 2] costs 10, from [0, 0] to [4, 4] costs 20, from [0, 0] to [6, 6] costs 30, from [0, 0] to [8, 8] costs 40, from [2, 2] to [4, 4] costs 10, from [2, 2] to [6, 6] costs 20, from [2, 2] to [8, 8] costs 30, from [4, 4] to [6, 6] costs 10, from [4, 4] to [8, 8] costs 20, from [6, 6] to [8, 8] costs 10.\n",
    "\n",
    "#Example of questions for code generation:\n",
    "\n",
    "\n",
    "#Example of questions for general answer:\n",
    "\n",
    "                                                                                                                                                                                                                                                                                                                                        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
